

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Landmark detection and cropping &#8212; Medusa</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/landmark_detection_and_cropping';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Command-line interface" href="../api/cli.html" />
    <link rel="prev" title="Face detection" href="face_detection.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Medusa: 4D face reconstruction and analysis
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Medusa installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/citation.html">Citation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="reconstruction.html">4D reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_representation.html">Data representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="rendering.html">Rendering</a></li>
<li class="toctree-l1"><a class="reference internal" href="analysis.html">Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="face_detection.html">Face detection</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Landmark detection and cropping</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../api/cli.html">Command-line interface</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/python.html">Python interface</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/python/analysis/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.analysis</span></code></a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/containers/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.containers</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/containers/fourD/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.containers.fourD</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/containers/results/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.containers.results</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/containers/threeD/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.containers.threeD</span></code></a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/crop/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.crop</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/crop/align_crop/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.crop.align_crop</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/crop/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.crop.base</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/crop/bbox_crop/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.crop.bbox_crop</span></code></a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/data/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.data</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/data/example_data/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.data.example_data</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/data/regenerate_example_recon_data/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.data.regenerate_example_recon_data</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/data/template_data/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.data.template_data</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/defaults/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.defaults</span></code></a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/detect/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.detect</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/detect/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.detect.base</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/detect/scrfd/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.detect.scrfd</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/detect/yunet/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.detect.yunet</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/epoch/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.epoch</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/geometry/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.geometry</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/io/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.io</span></code></a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/landmark/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.landmark</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/landmark/retinaface/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.landmark.retinaface</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/log/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.log</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/onnx/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.onnx</span></code></a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/preproc/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.preproc</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/preproc/align/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.preproc.align</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/preproc/filter/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.preproc.filter</span></code></a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/recognize/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recognize</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/recognize/retinaface/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recognize.retinaface</span></code></a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/recon/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/python/recon/flame/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.flame</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/python/recon/flame/deca/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.flame.deca</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/python/recon/flame/mica/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.flame.mica</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/python/recon/flame/base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.flame.base</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/python/recon/flame/decoders/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.flame.decoders</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/python/recon/flame/lbs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.flame.lbs</span></code></a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/python/recon/mpipe/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.mpipe</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/python/recon/mpipe/mpipe/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.mpipe.mpipe</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/recon/recon/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.recon.recon</span></code></a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/python/render/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.render</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/python/render/image/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.render.image</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/render/lights/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.render.lights</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/render/overlay/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.render.overlay</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/python/render/video/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.render.video</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/tracking/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.tracking</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/transforms/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">medusa.transforms</span></code></a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../misc/bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/for_developers.html">For developers</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/medusa-4D/medusa/master?urlpath=tree/tutorials/landmark_detection_and_cropping.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/medusa-4D/medusa" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/medusa-4D/medusa/edit/master/tutorials/landmark_detection_and_cropping.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/medusa-4D/medusa/issues/new?title=Issue%20on%20page%20%2Ftutorials/landmark_detection_and_cropping.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorials/landmark_detection_and_cropping.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Landmark detection and cropping</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#landmark-detection">Landmark detection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cropping">Cropping</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bounding-box-based-cropping">Bounding-box based cropping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#alignment-based-cropping">Alignment-based cropping</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="landmark-detection-and-cropping">
<h1>Landmark detection and cropping<a class="headerlink" href="#landmark-detection-and-cropping" title="Permalink to this heading">#</a></h1>
<p>As discussed in the face detection tutorial, there is a lot of preprocessing needed before we can feed images to the reconstruction models. One important step is <em>cropping</em>, which crops out the detected face(s) from the image standarizes the output into a new image with prespecified dimensions. Some models crop the image by specifying a bounding box, which is often constructed by creating a rectangular box around a set of estimated facial features (also called face <em>landmarks</em>).</p>
<p>Other models (like MICA, or any model based on Arcface for that matter) expect images not only to be cropped, but also <em>aligned</em>. Here, alignment means that certain key  facial landmarks of a cropped face are as close as possible relative to a template set of landmarks.</p>
<p>Medusa includes implementation of both bounding-box based as well as alignment-based “crop models”, <code class="docutils literal notranslate"><span class="pre">BboxCropModel</span></code> (used for DECA-based reconstruction models) and <code class="docutils literal notranslate"><span class="pre">AlignCropModel</span></code> (used for MICA). Note that the <code class="docutils literal notranslate"><span class="pre">Mediapipe</span></code> reconstruction model does not need cropping (which is performed by the <code class="docutils literal notranslate"><span class="pre">Mediapipe</span></code> model itself).</p>
<p>But before we discuss cropping, let’s discuss facial landmark detection, as it is central to both types of crop models.</p>
<section id="landmark-detection">
<h2>Landmark detection<a class="headerlink" href="#landmark-detection" title="Permalink to this heading">#</a></h2>
<p>Landmark detection usually detects a fixed set of key facial landmarks in images, like the tip of the nose, mouth corners, and face outline. In fact, in the detection tutorial, we have seen that Medusa’s detectors in fact also return a set of landmarks, albeit just five: left eye, right eye, left mouth corner, right mouth corner, and tip of the nose.</p>
<p>We’ll shown these landmarks (returned by the detection model) below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">medusa.data</span> <span class="kn">import</span> <span class="n">get_example_image</span>
<span class="kn">from</span> <span class="nn">medusa.detect</span> <span class="kn">import</span> <span class="n">SCRFDetector</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">draw_keypoints</span><span class="p">,</span> <span class="n">save_image</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">Video</span>

<span class="n">detector</span> <span class="o">=</span> <span class="n">SCRFDetector</span><span class="p">()</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">get_example_image</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">detector</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">byte</span><span class="p">(),</span> <span class="n">out</span><span class="p">[</span><span class="s1">&#39;lms&#39;</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;lms5.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;lms5.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f36c19cac309ff791750c39b43fdebd6d799c0f107d70aef2aac9057570b880e.png" src="../_images/f36c19cac309ff791750c39b43fdebd6d799c0f107d70aef2aac9057570b880e.png" />
</div>
</div>
<p>Although these five landmarks are sufficient for alignment (and is in fact used in the <code class="docutils literal notranslate"><span class="pre">AlignCropModel</span></code> class, as we’ll see later), they’re not ideal to base a bounding box on (as in the <code class="docutils literal notranslate"><span class="pre">BboxCropModel</span></code> class), because from the landmarks alone you do not know the full width and height of the face and therefore do not know how wide/tall the bounding box should be!</p>
<p>Fortunately, the kind folks at <a class="reference external" href="https://insightface.ai/">Insightface</a> did not only make their face detection model (used for Medusa’s <code class="docutils literal notranslate"><span class="pre">SCRFDectector</span></code> class) open source, but also their 2D and 3D landmark models, which output either 106 (2D) or 68 (3D) landmarks!</p>
<p>Medusa contains an efficient wrapper around these landmark models: <code class="docutils literal notranslate"><span class="pre">RetinafaceLandmarkModel</span></code>. Using the <code class="docutils literal notranslate"><span class="pre">model_name</span></code> parameter, you can determine whether you want to return 106 or 68 landmarks (use ‘1k3d68’ for 68 landmarks, or ‘2d106det’ for 106 landmarks); note that we discard the depth dimension for the 3D landmark model, so that the output is always <span class="math notranslate nohighlight">\(L\)</span> (number of landmarks) <span class="math notranslate nohighlight">\(\times 2\)</span>.</p>
<p>Let’s checkout the ‘2d106det’ model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">medusa.landmark</span> <span class="kn">import</span> <span class="n">RetinafaceLandmarkModel</span>

<span class="n">lm_model</span> <span class="o">=</span> <span class="n">RetinafaceLandmarkModel</span><span class="p">(</span><span class="s1">&#39;2d106det&#39;</span><span class="p">)</span>
<span class="n">out_106</span> <span class="o">=</span> <span class="n">lm_model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">out_106</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;conf&#39;, &#39;bbox&#39;, &#39;lms&#39;, &#39;img_idx&#39;, &#39;n_img&#39;])
</pre></div>
</div>
</div>
</div>
<p>As you can see, the landmark model outputs the face detection results (which it applied before landmark detection), but replaces the ‘lms’ data with the new landmarks:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">tuple</span><span class="p">(</span><span class="n">out_106</span><span class="p">[</span><span class="s1">&#39;lms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (batch, n_landmarks, XY)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 106, 2)
</pre></div>
</div>
</div>
</div>
<p>We can visualize these landmarks as before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">byte</span><span class="p">(),</span> <span class="n">out_106</span><span class="p">[</span><span class="s1">&#39;lms&#39;</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;lms106.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;lms106.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/8a2d6f89829c41aa716a3aa1c49c577cbb4b1a66bf55de546637b2c589f54b57.png" src="../_images/8a2d6f89829c41aa716a3aa1c49c577cbb4b1a66bf55de546637b2c589f54b57.png" />
</div>
</div>
<p>To show the difference with the 68-landmark model, we’ll run it again (this time with the ‘1k3d68’ model) and plot the detected landmarks on top of the previous image (106-lm model in red; 68-lm model in green):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lm_model</span> <span class="o">=</span> <span class="n">RetinafaceLandmarkModel</span><span class="p">(</span><span class="s1">&#39;1k3d68&#39;</span><span class="p">)</span>
<span class="n">out_68</span> <span class="o">=</span> <span class="n">lm_model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">draw</span><span class="p">,</span> <span class="n">out_68</span><span class="p">[</span><span class="s1">&#39;lms&#39;</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;lms106+68.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;lms106+68.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f8f29fa2d71423851e6dbdcdd345cf96bab26dbee87b3c204b74790890e0438f.png" src="../_images/f8f29fa2d71423851e6dbdcdd345cf96bab26dbee87b3c204b74790890e0438f.png" />
</div>
</div>
<p>Like most functionality in Medusa, the landmark model can be run on batches of images, like series of video frames! We show this below and visualize it using the <code class="docutils literal notranslate"><span class="pre">BatchResults</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">medusa.data</span> <span class="kn">import</span> <span class="n">get_example_video</span>
<span class="kn">from</span> <span class="nn">medusa.containers</span> <span class="kn">import</span> <span class="n">BatchResults</span>

<span class="n">lm_model</span> <span class="o">=</span> <span class="n">RetinafaceLandmarkModel</span><span class="p">(</span><span class="s1">&#39;2d106det&#39;</span><span class="p">)</span>
<span class="n">vid</span> <span class="o">=</span> <span class="n">get_example_video</span><span class="p">(</span><span class="n">return_videoloader</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">vid</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">lm_model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">lm_model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">BatchResults</span><span class="p">(</span><span class="o">**</span><span class="n">out</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="s1">&#39;./lms.mp4&#39;</span><span class="p">,</span> <span class="n">imgs</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">video</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">Video</span><span class="p">(</span><span class="s1">&#39;./lms.mp4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><video src="./lms.mp4" controls  >
      Your browser does not support the <code>video</code> element.
    </video></div></div>
</div>
<p>Note that, in addition to the landmarks from the landmark model, <code class="docutils literal notranslate"><span class="pre">BatchResults</span></code> also shows the bounding box and confidence score returned by the detector.</p>
</section>
<section id="cropping">
<h2>Cropping<a class="headerlink" href="#cropping" title="Permalink to this heading">#</a></h2>
<p>In Medusa, there are two approaches for cropping: a bounding-box based method and an alignment-based method. We’ll discuss these in turn.</p>
<section id="bounding-box-based-cropping">
<h3>Bounding-box based cropping<a class="headerlink" href="#bounding-box-based-cropping" title="Permalink to this heading">#</a></h3>
<p>In our bounding-box (bbox) based cropping method, we use a rectangular bounding box to “cut out” the face such that the face is roughly in the center of the image. You might think, ‘great, we can use the <code class="docutils literal notranslate"><span class="pre">bbox</span></code> from the face detection model outputs for this!’, but that isn’t as straightforward as it looks. First, this bbox is rectangular, while most reconstruction models (including DECA/EMOCA-based models in Medusa) expect square images (e.g., <span class="math notranslate nohighlight">\(224 \times 224\)</span>). Also, and this is more of a pragmatic issue, the cropping procedure should be <em>exactly the same</em> as the procedure used when training the reconstruction model. And it turns out that DECA and EMOCA, Medusa’s prime reconstruction models, used a very specific procedure.</p>
<p>In short, these models would do the following:</p>
<ol class="arabic simple">
<li><p>use a 68-landmark model to estimate facial landmarks</p></li>
<li><p>create a bbox based on the landmarks closest to the image borders</p></li>
<li><p>slightly enlarge the bbox</p></li>
<li><p>make the bbox square</p></li>
<li><p>use the final bbox to crop the image</p></li>
</ol>
<p>In Medusa, we implemented this procedure in the <code class="docutils literal notranslate"><span class="pre">BboxCropModel</span></code> class, which is nearly identical to the original DECA implementation, except that we use a faster and more accurate landmark estimation model (i.e., the <code class="docutils literal notranslate"><span class="pre">1k3d68</span></code> version of the <code class="docutils literal notranslate"><span class="pre">RetinafaceLandmarkModel</span></code>).</p>
<p>We’ll show you how this class is used below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">medusa.crop</span> <span class="kn">import</span> <span class="n">BboxCropModel</span>

<span class="c1"># 224 x 224 is the expected cropped image size for the DECA/EMOCA models</span>
<span class="n">crop_model</span> <span class="o">=</span> <span class="n">BboxCropModel</span><span class="p">(</span><span class="n">lms_model_name</span><span class="o">=</span><span class="s1">&#39;1k3d68&#39;</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">out_crop</span> <span class="o">=</span> <span class="n">crop_model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">out_crop</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;conf&#39;, &#39;bbox&#39;, &#39;lms&#39;, &#39;img_idx&#39;, &#39;n_img&#39;, &#39;imgs_crop&#39;, &#39;crop_mat&#39;])
</pre></div>
</div>
</div>
</div>
<p>Like the landmark model, the crop model outputs both the outputs from the detection model (<code class="docutils literal notranslate"><span class="pre">conf</span></code>, <code class="docutils literal notranslate"><span class="pre">lms</span></code>, etc) as well as three new outputs: <code class="docutils literal notranslate"><span class="pre">bbox</span></code> (the <em>new</em> bbox, which replaced the one from the face detection model), <code class="docutils literal notranslate"><span class="pre">imgs_crop</span></code> and <code class="docutils literal notranslate"><span class="pre">crop_mat</span></code>.</p>
<p>Below, we’ll run the detection model separately to compare the bbox returned by the detection model (in red) and the bbox created by the crop model (in green):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">draw_bounding_boxes</span>
<span class="kn">from</span> <span class="nn">medusa.detect</span> <span class="kn">import</span> <span class="n">SCRFDetector</span>

<span class="n">det_model</span> <span class="o">=</span> <span class="n">SCRFDetector</span><span class="p">()</span>
<span class="n">out_det</span> <span class="o">=</span> <span class="n">det_model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_bounding_boxes</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">byte</span><span class="p">(),</span> <span class="n">out_det</span><span class="p">[</span><span class="s1">&#39;bbox&#39;</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_bounding_boxes</span><span class="p">(</span><span class="n">draw</span><span class="p">,</span> <span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;bbox&#39;</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;bbox_compare.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;bbox_compare.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5214cb6f835f88efee985571249a5f6dda9f02406fcc2c41e2095dfc3cd32385.png" src="../_images/5214cb6f835f88efee985571249a5f6dda9f02406fcc2c41e2095dfc3cd32385.png" />
</div>
</div>
<p>Now, as the name suggests, <code class="docutils literal notranslate"><span class="pre">imgs_crop</span></code> contains the cropped images of each face detected in the original image. As expected, the image is now square and in the dimensions specified when initializing the crop model (i.e., <span class="math notranslate nohighlight">\(224 \times 224\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># N (detections) x 3 (RGB) x H x W</span>
<span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;imgs_crop&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 3, 224, 224])
</pre></div>
</div>
</div>
</div>
<p>which looks like the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_image</span><span class="p">(</span><span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;imgs_crop&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;crop.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;crop.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2c4a1d6cf0134de3cc4c056952de42540929f6067a9f886b780ffee3e2f369ee.png" src="../_images/2c4a1d6cf0134de3cc4c056952de42540929f6067a9f886b780ffee3e2f369ee.png" />
</div>
</div>
<p>This leaves us with <code class="docutils literal notranslate"><span class="pre">crop_mat</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">crop_mat</span> <span class="o">=</span> <span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;crop_mat&#39;</span><span class="p">]</span>
<span class="nb">tuple</span><span class="p">(</span><span class="n">crop_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># N (detections) x 3 x 3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 3, 3)
</pre></div>
</div>
</div>
</div>
<p>The ‘crop_mat’ output represents (for each detection) a <span class="math notranslate nohighlight">\(3 \times 3\)</span> affine matrix that represents (slightly simplified) the cropping operation as a similarity transform of the corners of the image to the corners of the bounding box. This matrix can then be used to warp the pixels of the original image to create the cropped image. Although <code class="docutils literal notranslate"><span class="pre">BboxCropModel</span></code> does this for you (and returns the results as <code class="docutils literal notranslate"><span class="pre">imgs_crop</span></code>), we’ll show below how this is in fact done using the <code class="docutils literal notranslate"><span class="pre">crop_mat</span></code>. We’ll use <code class="docutils literal notranslate"><span class="pre">warp_affine</span></code> from the awesome <a class="reference external" href="https://kornia.readthedocs.io/">Kornia</a> package:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">kornia.geometry.transform</span> <span class="kn">import</span> <span class="n">warp_affine</span>

<span class="c1"># warp_affine expects a N x 2 x 3 matrix, so we remove the last row</span>
<span class="n">img_crop</span> <span class="o">=</span> <span class="n">warp_affine</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;crop_mat&#39;</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dsize</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">img_crop</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;crop_manual.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;crop_manual.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/255b72cfa679215ea213c87fc27a15b150cfc2b94aa499e32f99e12f68e550d9.png" src="../_images/255b72cfa679215ea213c87fc27a15b150cfc2b94aa499e32f99e12f68e550d9.png" />
</div>
</div>
<p>So, in essence the <code class="docutils literal notranslate"><span class="pre">crop_mat</span></code> is a way to move between the original image space and the cropped image space. This means we can also project the cropped image back into the original image space using the <em>inverse</em> of the <code class="docutils literal notranslate"><span class="pre">crop_mat</span></code>!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">inv_crop_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;crop_mat&#39;</span><span class="p">])</span>
<span class="n">img_uncrop</span> <span class="o">=</span> <span class="n">warp_affine</span><span class="p">(</span><span class="n">img_crop</span><span class="p">,</span> <span class="n">inv_crop_mat</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dsize</span><span class="o">=</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">save_image</span><span class="p">(</span><span class="n">img_uncrop</span><span class="p">,</span> <span class="s1">&#39;uncrop.png&#39;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;uncrop.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6bbe58fd84376492669af9eb4a2b84e1d1d2b283b7e848b7bb1e53c9ff29f00c.png" src="../_images/6bbe58fd84376492669af9eb4a2b84e1d1d2b283b7e848b7bb1e53c9ff29f00c.png" />
</div>
</div>
<p>Crucially, the <code class="docutils literal notranslate"><span class="pre">crop_mat</span></code> can also be used to move points (rather than pixels), like landmarks, between the original and cropped image space. For example, if we would like to plot the landmarks (which are defined in the original image space) on the cropped image, we can project them in cropped image space as follows (using the <code class="docutils literal notranslate"><span class="pre">transform_points</span></code> function from Kornia):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">kornia.geometry.linalg</span> <span class="kn">import</span> <span class="n">transform_points</span>
<span class="n">lms_cropped</span> <span class="o">=</span> <span class="n">transform_points</span><span class="p">(</span><span class="n">crop_mat</span><span class="p">,</span> <span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;lms&#39;</span><span class="p">])</span>

<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">img_crop</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">byte</span><span class="p">(),</span> <span class="n">lms_cropped</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;lms_crop.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;lms_crop.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d910a7a4342ea2196ffd2dab1f56f505e4b4aa63b6e159fe439a0c7ce9c9c425.png" src="../_images/d910a7a4342ea2196ffd2dab1f56f505e4b4aa63b6e159fe439a0c7ce9c9c425.png" />
</div>
</div>
<p>This crop matrix is in fact also important for rendering 3D reconstruction results! We include the translation and scaling introduced by the cropping operation into the affine (world) matrix of the 3D object such that, when rendered, it is projected in the original image rather than the cropped image space!</p>
</section>
<section id="alignment-based-cropping">
<h3>Alignment-based cropping<a class="headerlink" href="#alignment-based-cropping" title="Permalink to this heading">#</a></h3>
<p>In addition to the bbox-based cropping model, Medusa also includes an alignment-based crop model: <code class="docutils literal notranslate"><span class="pre">AlignCropModel</span></code>. This model will align the face landmarks in the image to a template set of landmarks. The template used by the model, by default, is the set of five landmarks we have seen before, defined in an image space of <span class="math notranslate nohighlight">\(112 \times 112\)</span> pixels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">medusa.crop.align_crop</span> <span class="kn">import</span> <span class="n">TEMPLATE</span>
<span class="nb">print</span><span class="p">(</span><span class="n">TEMPLATE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[38.2946, 51.6963],
        [73.5318, 51.5014],
        [56.0252, 71.7366],
        [41.5493, 92.3655],
        [70.7299, 92.2041]])
</pre></div>
</div>
</div>
</div>
<p>which we can show as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">background</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">))</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">background</span><span class="p">,</span> <span class="n">TEMPLATE</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;lm_template.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;lm_template.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4d827ab277107874e902c56c06d84064f7cd9be8198ce62be496063623202c00.png" src="../_images/4d827ab277107874e902c56c06d84064f7cd9be8198ce62be496063623202c00.png" />
</div>
</div>
<p>To align the face landmarks from the image (provided by the face detection model) to the template, the <code class="docutils literal notranslate"><span class="pre">AlignCropModel</span></code> will estimate a similarity transform (giving us a crop matrix again!):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">medusa.crop</span> <span class="kn">import</span> <span class="n">AlignCropModel</span>

<span class="n">crop_model</span> <span class="o">=</span> <span class="n">AlignCropModel</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">))</span>
<span class="n">out_crop</span> <span class="o">=</span> <span class="n">crop_model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">out_crop</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;imgs_crop&#39;, &#39;crop_mat&#39;, &#39;conf&#39;, &#39;bbox&#39;, &#39;lms&#39;, &#39;img_idx&#39;, &#39;n_img&#39;])
</pre></div>
</div>
</div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">lms</span></code> represents the aligned landmarks. Let’s see how well the model did by plotting both the template landmarks (in red) and the aligned landmarks (in green) on top of the cropped image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;imgs_crop&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">byte</span><span class="p">(),</span> <span class="n">TEMPLATE</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Note that the aligned landmarks are (by default) in original image space, so </span>
<span class="n">lms</span> <span class="o">=</span> <span class="n">transform_points</span><span class="p">(</span><span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;crop_mat&#39;</span><span class="p">],</span> <span class="n">out_crop</span><span class="p">[</span><span class="s1">&#39;lms&#39;</span><span class="p">])</span>
<span class="n">draw</span> <span class="o">=</span> <span class="n">draw_keypoints</span><span class="p">(</span><span class="n">draw</span><span class="p">,</span> <span class="n">lms</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">save_image</span><span class="p">(</span><span class="n">draw</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="s1">&#39;lm_aligned.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;lm_aligned.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/efbb86f960471e2b40b3f05dd0d70eea5af787315924e6a5d233e4f4c85a3ce8.png" src="../_images/efbb86f960471e2b40b3f05dd0d70eea5af787315924e6a5d233e4f4c85a3ce8.png" />
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">AlignCropModel</span></code> (like the <code class="docutils literal notranslate"><span class="pre">BboxCropModel</span></code> for that matter) also work on batches of images, which can be visualized using <code class="docutils literal notranslate"><span class="pre">BatchResults</span></code>. Only issue is that <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> does not support drawing rotated bounding boxes, so instead we visualize the aligned images in cropped image space:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vid</span> <span class="o">=</span> <span class="n">get_example_video</span><span class="p">(</span><span class="n">return_videoloader</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">vid</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">lm_model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">crop_model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">BatchResults</span><span class="p">(</span><span class="o">**</span><span class="n">out</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">sort_faces</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="s1">&#39;./align_crop.mp4&#39;</span><span class="p">,</span> <span class="n">imgs</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">video</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_cropped</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">crop_size</span><span class="o">=</span><span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">),</span> <span class="n">template</span><span class="o">=</span><span class="n">TEMPLATE</span><span class="p">)</span>

<span class="n">Video</span><span class="p">(</span><span class="s1">&#39;./align_crop.mp4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><video src="./align_crop.mp4" controls  >
      Your browser does not support the <code>video</code> element.
    </video></div></div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="face_detection.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Face detection</p>
      </div>
    </a>
    <a class="right-next"
       href="../api/cli.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Command-line interface</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#landmark-detection">Landmark detection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cropping">Cropping</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bounding-box-based-cropping">Bounding-box based cropping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#alignment-based-cropping">Alignment-based cropping</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lukas Snoek
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  Developed at the University of Glasgow
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>